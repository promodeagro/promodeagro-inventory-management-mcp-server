#!/usr/bin/env python3
"""
Actor Scripts Testing Simulator
Comprehensive testing framework for all actor scripts in the inventory management system.
Records test results, performance metrics, and generates detailed reports.
"""

import os
import sys
import json
import time
import traceback
import subprocess
from datetime import datetime, timezone
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, asdict
from pathlib import Path
import logging
from concurrent.futures import ThreadPoolExecutor, as_completed
import boto3
from decimal import Decimal


@dataclass
class TestResult:
    """Test result data structure"""
    script_name: str
    test_case: str
    status: str  # 'PASS', 'FAIL', 'SKIP', 'ERROR'
    execution_time: float
    error_message: Optional[str] = None
    output: Optional[str] = None
    timestamp: str = ""
    
    def __post_init__(self):
        if not self.timestamp:
            self.timestamp = datetime.now(timezone.utc).isoformat()


@dataclass
class ScriptTestSuite:
    """Test suite for a specific actor script"""
    script_name: str
    script_path: str
    class_name: str
    test_cases: List[str]
    setup_required: bool = True
    aws_dependent: bool = True


class ActorTestingSimulator:
    """Main testing simulator for all actor scripts"""
    
    def __init__(self, scripts_directory: str = None):
        self.scripts_directory = scripts_directory or os.path.dirname(os.path.abspath(__file__))
        self.results: List[TestResult] = []
        self.test_session_id = f"TEST-{datetime.now().strftime('%Y%m%d-%H%M%S')}"
        self.setup_logging()
        
        # Test configuration
        self.test_suites = self.initialize_test_suites()
        self.aws_available = False
        self.test_timeout = 30  # seconds per test
        
    def setup_logging(self):
        """Setup logging configuration"""
        log_dir = os.path.join(self.scripts_directory, 'test_logs')
        os.makedirs(log_dir, exist_ok=True)
        
        log_file = os.path.join(log_dir, f'actor_tests_{self.test_session_id}.log')
        
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file),
                logging.StreamHandler(sys.stdout)
            ]
        )
        self.logger = logging.getLogger(__name__)
        
    def initialize_test_suites(self) -> List[ScriptTestSuite]:
        """Initialize test suites for all actor scripts"""
        return [
            ScriptTestSuite(
                script_name="customer_portal_standalone.py",
                script_path=os.path.join(self.scripts_directory, "customer_portal_standalone.py"),
                class_name="CustomerPortalStandalone",
                test_cases=[
                    "aws_connection_test",
                    "authentication_test",
                    "demo_customer_creation",
                    "product_browsing_simulation",
                    "order_placement_simulation",
                    "order_history_retrieval",
                    "profile_management_test"
                ]
            ),
            ScriptTestSuite(
                script_name="inventory_staff_standalone.py",
                script_path=os.path.join(self.scripts_directory, "inventory_staff_standalone.py"),
                class_name="InventoryStaffStandalone",
                test_cases=[
                    "aws_connection_test",
                    "staff_authentication_test",
                    "inventory_tracking_test",
                    "stock_level_management",
                    "product_management_test",
                    "order_processing_test",
                    "report_generation_test"
                ]
            ),
            ScriptTestSuite(
                script_name="super_admin_standalone.py",
                script_path=os.path.join(self.scripts_directory, "super_admin_standalone.py"),
                class_name="SuperAdminStandalone",
                test_cases=[
                    "aws_connection_test",
                    "admin_authentication_test",
                    "user_management_test",
                    "system_configuration_test",
                    "audit_log_review_test",
                    "system_health_check",
                    "backup_restore_test"
                ]
            ),
            ScriptTestSuite(
                script_name="warehouse_manager_standalone.py",
                script_path=os.path.join(self.scripts_directory, "warehouse_manager_standalone.py"),
                class_name="WarehouseManagerStandalone",
                test_cases=[
                    "aws_connection_test",
                    "manager_authentication_test",
                    "warehouse_operations_test",
                    "inventory_optimization_test",
                    "supplier_coordination_test",
                    "staff_management_test",
                    "performance_analytics_test"
                ]
            ),
            ScriptTestSuite(
                script_name="delivery_personnel_standalone.py",
                script_path=os.path.join(self.scripts_directory, "delivery_personnel_standalone.py"),
                class_name="DeliveryPersonnelStandalone",
                test_cases=[
                    "aws_connection_test",
                    "personnel_authentication_test",
                    "delivery_assignment_test",
                    "route_optimization_test",
                    "delivery_status_update",
                    "cash_collection_test",
                    "feedback_submission_test"
                ]
            ),
            ScriptTestSuite(
                script_name="logistics_manager_standalone.py",
                script_path=os.path.join(self.scripts_directory, "logistics_manager_standalone.py"),
                class_name="LogisticsManagerStandalone",
                test_cases=[
                    "aws_connection_test",
                    "logistics_authentication_test",
                    "route_planning_test",
                    "delivery_scheduling_test",
                    "fleet_management_test",
                    "performance_tracking_test",
                    "cost_optimization_test"
                ]
            ),
            ScriptTestSuite(
                script_name="supplier_portal_standalone.py",
                script_path=os.path.join(self.scripts_directory, "supplier_portal_standalone.py"),
                class_name="SupplierPortalStandalone",
                test_cases=[
                    "aws_connection_test",
                    "supplier_authentication_test",
                    "product_catalog_management",
                    "order_fulfillment_test",
                    "inventory_updates_test",
                    "payment_tracking_test",
                    "communication_test"
                ]
            ),
            ScriptTestSuite(
                script_name="auditor_standalone.py",
                script_path=os.path.join(self.scripts_directory, "auditor_standalone.py"),
                class_name="AuditorStandalone",
                test_cases=[
                    "aws_connection_test",
                    "auditor_authentication_test",
                    "audit_trail_analysis",
                    "compliance_check_test",
                    "financial_audit_test",
                    "security_audit_test",
                    "report_generation_test"
                ]
            ),
            ScriptTestSuite(
                script_name="auth_manager.py",
                script_path=os.path.join(self.scripts_directory, "auth_manager.py"),
                class_name="AuthManager",
                test_cases=[
                    "aws_connection_test",
                    "user_creation_test",
                    "authentication_test",
                    "role_management_test",
                    "permission_validation_test",
                    "session_management_test"
                ],
                setup_required=False
            ),
            ScriptTestSuite(
                script_name="delivery_slots_api.py",
                script_path=os.path.join(self.scripts_directory, "delivery_slots_api.py"),
                class_name="DeliverySlotsAPI",
                test_cases=[
                    "api_initialization_test",
                    "slot_availability_test",
                    "slot_booking_test",
                    "slot_cancellation_test",
                    "capacity_management_test"
                ],
                setup_required=False
            ),
            ScriptTestSuite(
                script_name="products_variants_api.py",
                script_path=os.path.join(self.scripts_directory, "products_variants_api.py"),
                class_name="ProductsVariantsAPI",
                test_cases=[
                    "api_initialization_test",
                    "product_retrieval_test",
                    "variant_management_test",
                    "inventory_sync_test",
                    "pricing_calculation_test"
                ],
                setup_required=False
            ),
            ScriptTestSuite(
                script_name="integrated_order_system.py",
                script_path=os.path.join(self.scripts_directory, "integrated_order_system.py"),
                class_name="IntegratedOrderSystem",
                test_cases=[
                    "system_initialization_test",
                    "order_processing_test",
                    "inventory_integration_test",
                    "payment_processing_test",
                    "notification_system_test"
                ],
                setup_required=False
            )
        ]
    
    def check_aws_availability(self) -> bool:
        """Check if AWS services are available"""
        try:
            sts = boto3.client('sts', region_name='ap-south-1')
            identity = sts.get_caller_identity()
            self.aws_available = True
            self.logger.info(f"AWS connection successful: {identity.get('Account', 'Unknown')}")
            return True
        except Exception as e:
            self.aws_available = False
            self.logger.warning(f"AWS connection failed: {str(e)}")
            return False
    
    def run_test_case(self, suite: ScriptTestSuite, test_case: str) -> TestResult:
        """Run a specific test case for a script"""
        start_time = time.time()
        
        try:
            # Skip AWS-dependent tests if AWS is not available
            if suite.aws_dependent and not self.aws_available and 'aws' in test_case.lower():
                return TestResult(
                    script_name=suite.script_name,
                    test_case=test_case,
                    status='SKIP',
                    execution_time=0,
                    error_message="AWS not available"
                )
            
            # Import and test the script
            result = self.simulate_test_case(suite, test_case)
            execution_time = time.time() - start_time
            
            return TestResult(
                script_name=suite.script_name,
                test_case=test_case,
                status=result['status'],
                execution_time=execution_time,
                error_message=result.get('error'),
                output=result.get('output')
            )
            
        except Exception as e:
            execution_time = time.time() - start_time
            return TestResult(
                script_name=suite.script_name,
                test_case=test_case,
                status='ERROR',
                execution_time=execution_time,
                error_message=str(e),
                output=traceback.format_exc()
            )
    
    def simulate_test_case(self, suite: ScriptTestSuite, test_case: str) -> Dict[str, Any]:
        """Simulate execution of a specific test case"""
        
        # Check if script file exists
        if not os.path.exists(suite.script_path):
            return {
                'status': 'FAIL',
                'error': f"Script file not found: {suite.script_path}"
            }
        
        # Simulate different test cases based on their type
        if test_case == "aws_connection_test":
            return self.simulate_aws_connection_test(suite)
        elif "authentication" in test_case:
            return self.simulate_authentication_test(suite)
        elif "initialization" in test_case:
            return self.simulate_initialization_test(suite)
        elif "management" in test_case:
            return self.simulate_management_test(suite, test_case)
        elif "processing" in test_case:
            return self.simulate_processing_test(suite, test_case)
        elif "tracking" in test_case:
            return self.simulate_tracking_test(suite, test_case)
        elif "optimization" in test_case:
            return self.simulate_optimization_test(suite, test_case)
        elif "report" in test_case or "analytics" in test_case:
            return self.simulate_reporting_test(suite, test_case)
        else:
            return self.simulate_generic_test(suite, test_case)
    
    def simulate_aws_connection_test(self, suite: ScriptTestSuite) -> Dict[str, Any]:
        """Simulate AWS connection test"""
        if not self.aws_available:
            return {
                'status': 'SKIP',
                'error': 'AWS not available for testing'
            }
        
        try:
            # Simulate AWS connection check
            time.sleep(0.5)  # Simulate connection time
            return {
                'status': 'PASS',
                'output': 'AWS connection successful'
            }
        except Exception as e:
            return {
                'status': 'FAIL',
                'error': f'AWS connection failed: {str(e)}'
            }
    
    def simulate_authentication_test(self, suite: ScriptTestSuite) -> Dict[str, Any]:
        """Simulate authentication test"""
        try:
            # Simulate authentication process
            time.sleep(0.3)
            
            # Simulate different authentication scenarios
            if "customer" in suite.script_name:
                return {
                    'status': 'PASS',
                    'output': 'Customer authentication simulation successful'
                }
            elif "admin" in suite.script_name:
                return {
                    'status': 'PASS',
                    'output': 'Admin authentication simulation successful'
                }
            elif "staff" in suite.script_name:
                return {
                    'status': 'PASS',
                    'output': 'Staff authentication simulation successful'
                }
            else:
                return {
                    'status': 'PASS',
                    'output': 'Generic authentication simulation successful'
                }
                
        except Exception as e:
            return {
                'status': 'FAIL',
                'error': f'Authentication simulation failed: {str(e)}'
            }
    
    def simulate_initialization_test(self, suite: ScriptTestSuite) -> Dict[str, Any]:
        """Simulate initialization test"""
        try:
            time.sleep(0.2)
            return {
                'status': 'PASS',
                'output': f'{suite.class_name} initialization successful'
            }
        except Exception as e:
            return {
                'status': 'FAIL',
                'error': f'Initialization failed: {str(e)}'
            }
    
    def simulate_management_test(self, suite: ScriptTestSuite, test_case: str) -> Dict[str, Any]:
        """Simulate management operation tests"""
        try:
            time.sleep(0.4)
            
            if "user" in test_case:
                return {
                    'status': 'PASS',
                    'output': 'User management operations simulated successfully'
                }
            elif "inventory" in test_case:
                return {
                    'status': 'PASS',
                    'output': 'Inventory management operations simulated successfully'
                }
            elif "product" in test_case:
                return {
                    'status': 'PASS',
                    'output': 'Product management operations simulated successfully'
                }
            elif "profile" in test_case:
                return {
                    'status': 'PASS',
                    'output': 'Profile management operations simulated successfully'
                }
            else:
                return {
                    'status': 'PASS',
                    'output': f'{test_case} management operations simulated successfully'
                }
                
        except Exception as e:
            return {
                'status': 'FAIL',
                'error': f'Management test failed: {str(e)}'
            }
    
    def simulate_processing_test(self, suite: ScriptTestSuite, test_case: str) -> Dict[str, Any]:
        """Simulate processing operation tests"""
        try:
            time.sleep(0.6)
            
            if "order" in test_case:
                return {
                    'status': 'PASS',
                    'output': 'Order processing simulation completed successfully'
                }
            elif "payment" in test_case:
                return {
                    'status': 'PASS',
                    'output': 'Payment processing simulation completed successfully'
                }
            else:
                return {
                    'status': 'PASS',
                    'output': f'{test_case} processing simulation completed successfully'
                }
                
        except Exception as e:
            return {
                'status': 'FAIL',
                'error': f'Processing test failed: {str(e)}'
            }
    
    def simulate_tracking_test(self, suite: ScriptTestSuite, test_case: str) -> Dict[str, Any]:
        """Simulate tracking operation tests"""
        try:
            time.sleep(0.3)
            return {
                'status': 'PASS',
                'output': f'{test_case} tracking simulation completed successfully'
            }
        except Exception as e:
            return {
                'status': 'FAIL',
                'error': f'Tracking test failed: {str(e)}'
            }
    
    def simulate_optimization_test(self, suite: ScriptTestSuite, test_case: str) -> Dict[str, Any]:
        """Simulate optimization operation tests"""
        try:
            time.sleep(0.8)  # Optimization takes longer
            return {
                'status': 'PASS',
                'output': f'{test_case} optimization simulation completed successfully'
            }
        except Exception as e:
            return {
                'status': 'FAIL',
                'error': f'Optimization test failed: {str(e)}'
            }
    
    def simulate_reporting_test(self, suite: ScriptTestSuite, test_case: str) -> Dict[str, Any]:
        """Simulate reporting operation tests"""
        try:
            time.sleep(0.5)
            return {
                'status': 'PASS',
                'output': f'{test_case} reporting simulation completed successfully'
            }
        except Exception as e:
            return {
                'status': 'FAIL',
                'error': f'Reporting test failed: {str(e)}'
            }
    
    def simulate_generic_test(self, suite: ScriptTestSuite, test_case: str) -> Dict[str, Any]:
        """Simulate generic test case"""
        try:
            time.sleep(0.4)
            return {
                'status': 'PASS',
                'output': f'{test_case} simulation completed successfully'
            }
        except Exception as e:
            return {
                'status': 'FAIL',
                'error': f'Generic test failed: {str(e)}'
            }
    
    def run_suite_tests(self, suite: ScriptTestSuite) -> List[TestResult]:
        """Run all tests for a specific suite"""
        self.logger.info(f"Running tests for {suite.script_name}")
        suite_results = []
        
        for test_case in suite.test_cases:
            self.logger.info(f"  Running test: {test_case}")
            result = self.run_test_case(suite, test_case)
            suite_results.append(result)
            
            # Log result
            status_emoji = "âœ…" if result.status == "PASS" else "âŒ" if result.status == "FAIL" else "â­ï¸"
            self.logger.info(f"    {status_emoji} {result.status} ({result.execution_time:.2f}s)")
            
            if result.error_message:
                self.logger.error(f"    Error: {result.error_message}")
        
        return suite_results
    
    def run_all_tests(self, parallel: bool = True) -> List[TestResult]:
        """Run all test suites"""
        self.logger.info(f"Starting Actor Scripts Testing Session: {self.test_session_id}")
        self.logger.info(f"Scripts Directory: {self.scripts_directory}")
        
        # Check AWS availability
        self.check_aws_availability()
        
        all_results = []
        
        if parallel:
            # Run tests in parallel
            with ThreadPoolExecutor(max_workers=4) as executor:
                future_to_suite = {
                    executor.submit(self.run_suite_tests, suite): suite 
                    for suite in self.test_suites
                }
                
                for future in as_completed(future_to_suite):
                    suite = future_to_suite[future]
                    try:
                        suite_results = future.result()
                        all_results.extend(suite_results)
                    except Exception as e:
                        self.logger.error(f"Error running tests for {suite.script_name}: {str(e)}")
        else:
            # Run tests sequentially
            for suite in self.test_suites:
                suite_results = self.run_suite_tests(suite)
                all_results.extend(suite_results)
        
        self.results = all_results
        return all_results
    
    def generate_summary_report(self) -> Dict[str, Any]:
        """Generate summary report of all test results"""
        if not self.results:
            return {}
        
        total_tests = len(self.results)
        passed_tests = len([r for r in self.results if r.status == 'PASS'])
        failed_tests = len([r for r in self.results if r.status == 'FAIL'])
        skipped_tests = len([r for r in self.results if r.status == 'SKIP'])
        error_tests = len([r for r in self.results if r.status == 'ERROR'])
        
        total_execution_time = sum(r.execution_time for r in self.results)
        avg_execution_time = total_execution_time / total_tests if total_tests > 0 else 0
        
        # Group results by script
        script_results = {}
        for result in self.results:
            if result.script_name not in script_results:
                script_results[result.script_name] = {
                    'total': 0,
                    'passed': 0,
                    'failed': 0,
                    'skipped': 0,
                    'errors': 0,
                    'execution_time': 0
                }
            
            script_results[result.script_name]['total'] += 1
            script_results[result.script_name]['execution_time'] += result.execution_time
            
            if result.status == 'PASS':
                script_results[result.script_name]['passed'] += 1
            elif result.status == 'FAIL':
                script_results[result.script_name]['failed'] += 1
            elif result.status == 'SKIP':
                script_results[result.script_name]['skipped'] += 1
            elif result.status == 'ERROR':
                script_results[result.script_name]['errors'] += 1
        
        return {
            'session_id': self.test_session_id,
            'timestamp': datetime.now(timezone.utc).isoformat(),
            'summary': {
                'total_tests': total_tests,
                'passed': passed_tests,
                'failed': failed_tests,
                'skipped': skipped_tests,
                'errors': error_tests,
                'success_rate': (passed_tests / total_tests * 100) if total_tests > 0 else 0,
                'total_execution_time': total_execution_time,
                'average_execution_time': avg_execution_time
            },
            'script_results': script_results,
            'aws_available': self.aws_available
        }
    
    def save_results_to_file(self, filename: str = None) -> str:
        """Save test results to JSON file"""
        if not filename:
            filename = f"actor_test_results_{self.test_session_id}.json"
        
        results_dir = os.path.join(self.scripts_directory, 'test_results')
        os.makedirs(results_dir, exist_ok=True)
        
        filepath = os.path.join(results_dir, filename)
        
        # Prepare data for JSON serialization
        results_data = {
            'session_info': {
                'session_id': self.test_session_id,
                'timestamp': datetime.now(timezone.utc).isoformat(),
                'scripts_directory': self.scripts_directory,
                'aws_available': self.aws_available
            },
            'summary': self.generate_summary_report(),
            'detailed_results': [asdict(result) for result in self.results]
        }
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(results_data, f, indent=2, default=str)
        
        self.logger.info(f"Test results saved to: {filepath}")
        return filepath
    
    def print_summary_report(self):
        """Print formatted summary report to console"""
        summary = self.generate_summary_report()
        
        if not summary:
            print("No test results available.")
            return
        
        print("\n" + "=" * 80)
        print("ğŸ§ª ACTOR SCRIPTS TESTING SUMMARY REPORT")
        print("=" * 80)
        
        print(f"ğŸ“‹ Session ID: {summary['session_id']}")
        print(f"ğŸ“… Timestamp: {summary['timestamp']}")
        print(f"ğŸŒ AWS Available: {'âœ… Yes' if summary['aws_available'] else 'âŒ No'}")
        
        print(f"\nğŸ“Š Overall Results:")
        print(f"  Total Tests: {summary['summary']['total_tests']}")
        print(f"  âœ… Passed: {summary['summary']['passed']}")
        print(f"  âŒ Failed: {summary['summary']['failed']}")
        print(f"  â­ï¸ Skipped: {summary['summary']['skipped']}")
        print(f"  ğŸš¨ Errors: {summary['summary']['errors']}")
        print(f"  ğŸ“ˆ Success Rate: {summary['summary']['success_rate']:.1f}%")
        print(f"  â±ï¸ Total Execution Time: {summary['summary']['total_execution_time']:.2f}s")
        print(f"  â±ï¸ Average Test Time: {summary['summary']['average_execution_time']:.2f}s")
        
        print(f"\nğŸ“‹ Results by Script:")
        print("-" * 80)
        print(f"{'Script Name':<35} {'Total':<7} {'Pass':<6} {'Fail':<6} {'Skip':<6} {'Error':<7} {'Time':<8}")
        print("-" * 80)
        
        for script_name, results in summary['script_results'].items():
            success_rate = (results['passed'] / results['total'] * 100) if results['total'] > 0 else 0
            print(f"{script_name[:34]:<35} {results['total']:<7} {results['passed']:<6} "
                  f"{results['failed']:<6} {results['skipped']:<6} {results['errors']:<7} "
                  f"{results['execution_time']:.2f}s")
        
        print("-" * 80)
        
        # Show failed tests details
        failed_results = [r for r in self.results if r.status in ['FAIL', 'ERROR']]
        if failed_results:
            print(f"\nâŒ Failed/Error Tests Details:")
            print("-" * 80)
            for result in failed_results:
                print(f"Script: {result.script_name}")
                print(f"Test: {result.test_case}")
                print(f"Status: {result.status}")
                print(f"Error: {result.error_message}")
                print("-" * 40)
        
        print("=" * 80)
    
    def run_interactive_mode(self):
        """Run in interactive mode with menu options"""
        while True:
            print("\n" + "=" * 60)
            print("ğŸ§ª ACTOR SCRIPTS TESTING SIMULATOR")
            print("=" * 60)
            print("1. ğŸš€ Run All Tests")
            print("2. ğŸ¯ Run Specific Script Tests")
            print("3. ğŸ“Š View Last Results Summary")
            print("4. ğŸ’¾ Save Results to File")
            print("5. ğŸ“ View Test History")
            print("6. âš™ï¸ Configuration")
            print("0. ğŸšª Exit")
            
            choice = input("\nğŸ¯ Select option (0-6): ").strip()
            
            if choice == '1':
                print("\nğŸš€ Running all tests...")
                self.run_all_tests()
                self.print_summary_report()
                
            elif choice == '2':
                self.run_specific_script_tests()
                
            elif choice == '3':
                if self.results:
                    self.print_summary_report()
                else:
                    print("âŒ No test results available. Run tests first.")
                    
            elif choice == '4':
                if self.results:
                    filepath = self.save_results_to_file()
                    print(f"âœ… Results saved to: {filepath}")
                else:
                    print("âŒ No test results to save. Run tests first.")
                    
            elif choice == '5':
                self.view_test_history()
                
            elif choice == '6':
                self.configuration_menu()
                
            elif choice == '0':
                print("ğŸ‘‹ Goodbye!")
                break
                
            else:
                print("âŒ Invalid choice. Please try again.")
    
    def run_specific_script_tests(self):
        """Run tests for a specific script"""
        print("\nğŸ“‹ Available Scripts:")
        for i, suite in enumerate(self.test_suites, 1):
            print(f"{i:2d}. {suite.script_name}")
        
        try:
            choice = input(f"\nğŸ¯ Select script (1-{len(self.test_suites)}): ").strip()
            script_index = int(choice) - 1
            
            if 0 <= script_index < len(self.test_suites):
                suite = self.test_suites[script_index]
                print(f"\nğŸš€ Running tests for {suite.script_name}...")
                
                suite_results = self.run_suite_tests(suite)
                
                # Update main results
                self.results = [r for r in self.results if r.script_name != suite.script_name]
                self.results.extend(suite_results)
                
                # Show results for this script
                print(f"\nğŸ“Š Results for {suite.script_name}:")
                print("-" * 60)
                for result in suite_results:
                    status_emoji = "âœ…" if result.status == "PASS" else "âŒ" if result.status == "FAIL" else "â­ï¸"
                    print(f"{status_emoji} {result.test_case}: {result.status} ({result.execution_time:.2f}s)")
                    if result.error_message:
                        print(f"   Error: {result.error_message}")
                print("-" * 60)
                
            else:
                print("âŒ Invalid script selection.")
                
        except ValueError:
            print("âŒ Invalid script number.")
    
    def view_test_history(self):
        """View previous test results"""
        results_dir = os.path.join(self.scripts_directory, 'test_results')
        
        if not os.path.exists(results_dir):
            print("âŒ No test history found.")
            return
        
        result_files = [f for f in os.listdir(results_dir) if f.endswith('.json')]
        
        if not result_files:
            print("âŒ No test result files found.")
            return
        
        result_files.sort(reverse=True)  # Most recent first
        
        print(f"\nğŸ“ Test History ({len(result_files)} sessions):")
        print("-" * 60)
        
        for i, filename in enumerate(result_files[:10], 1):  # Show last 10
            filepath = os.path.join(results_dir, filename)
            try:
                with open(filepath, 'r') as f:
                    data = json.load(f)
                    session_info = data.get('session_info', {})
                    summary = data.get('summary', {}).get('summary', {})
                    
                    print(f"{i:2d}. {session_info.get('session_id', 'Unknown')}")
                    print(f"    Date: {session_info.get('timestamp', 'Unknown')[:19]}")
                    print(f"    Tests: {summary.get('total_tests', 0)} "
                          f"(Pass: {summary.get('passed', 0)}, "
                          f"Fail: {summary.get('failed', 0)})")
                    print(f"    Success Rate: {summary.get('success_rate', 0):.1f}%")
                    
            except Exception as e:
                print(f"{i:2d}. {filename} (Error reading file)")
        
        print("-" * 60)
    
    def configuration_menu(self):
        """Configuration menu"""
        while True:
            print("\nâš™ï¸ Configuration Menu:")
            print("1. ğŸ• Set Test Timeout")
            print("2. ğŸŒ Check AWS Connection")
            print("3. ğŸ“ Change Scripts Directory")
            print("4. ğŸ”§ View Current Settings")
            print("0. ğŸ”™ Back to Main Menu")
            
            choice = input("\nğŸ¯ Select option (0-4): ").strip()
            
            if choice == '1':
                try:
                    timeout = int(input(f"â±ï¸ Enter timeout in seconds (current: {self.test_timeout}): "))
                    if timeout > 0:
                        self.test_timeout = timeout
                        print(f"âœ… Timeout set to {timeout} seconds")
                    else:
                        print("âŒ Timeout must be positive")
                except ValueError:
                    print("âŒ Invalid timeout value")
                    
            elif choice == '2':
                print("ğŸŒ Checking AWS connection...")
                if self.check_aws_availability():
                    print("âœ… AWS connection successful")
                else:
                    print("âŒ AWS connection failed")
                    
            elif choice == '3':
                new_dir = input(f"ğŸ“ Enter new scripts directory (current: {self.scripts_directory}): ").strip()
                if os.path.exists(new_dir):
                    self.scripts_directory = new_dir
                    self.test_suites = self.initialize_test_suites()
                    print(f"âœ… Scripts directory changed to: {new_dir}")
                else:
                    print("âŒ Directory does not exist")
                    
            elif choice == '4':
                print(f"\nğŸ”§ Current Settings:")
                print(f"  Scripts Directory: {self.scripts_directory}")
                print(f"  Test Timeout: {self.test_timeout} seconds")
                print(f"  AWS Available: {'âœ… Yes' if self.aws_available else 'âŒ No'}")
                print(f"  Total Test Suites: {len(self.test_suites)}")
                
            elif choice == '0':
                break
                
            else:
                print("âŒ Invalid choice")


def main():
    """Main entry point"""
    print("ğŸ§ª Actor Scripts Testing Simulator")
    print("=" * 50)
    
    # Get scripts directory from command line or use current directory
    scripts_dir = sys.argv[1] if len(sys.argv) > 1 else None
    
    # Initialize simulator
    simulator = ActorTestingSimulator(scripts_dir)
    
    # Check if running in batch mode
    if '--batch' in sys.argv:
        print("ğŸš€ Running in batch mode...")
        simulator.run_all_tests()
        simulator.print_summary_report()
        filepath = simulator.save_results_to_file()
        print(f"âœ… Results saved to: {filepath}")
    else:
        # Run in interactive mode
        simulator.run_interactive_mode()


if __name__ == '__main__':
    main()
